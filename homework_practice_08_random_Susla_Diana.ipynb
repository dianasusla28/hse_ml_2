{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "homework-practice-08-random-Susla-Diana.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYp0bXOFK-hP"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
        "\n",
        "### Общая информация\n",
        "Дата выдачи: 05.02.2021\n",
        "\n",
        "Мягкий дедлайн: 01:59MSK 21.02.2021\n",
        "\n",
        "Жесткий дедлайн: 01:59MSK 24.02.2021\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "### Формат сдачи\n",
        "Задания сдаются через систему anytask. Посылка должна содержать:\n",
        "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
        "\n",
        "Username — ваша фамилия и имя на латинице именно в таком порядке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY8vT0W_K-hR"
      },
      "source": [
        "### О задании\n",
        "\n",
        "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
        "\n",
        "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
        "\n",
        "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
        "$$\\tilde \\varphi(x) = (\n",
        "\\cos (w_1^T x + b_1),\n",
        "\\dots,\n",
        "\\cos (w_n^T x + b_n)\n",
        "),$$\n",
        "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
        "\n",
        "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
        "\n",
        "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y5alWQDydl1"
      },
      "source": [
        "Алгоритм\r\n",
        "\r\n",
        "Вам потребуется реализовать следующий алгоритм:\r\n",
        "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\r\n",
        "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\r\n",
        "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\r\n",
        "4. Сформировать n_features новых признаков по формулам, приведённым выше.\r\n",
        "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\r\n",
        "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_sGunb7K-hS"
      },
      "source": [
        "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyG6dBfjK-hS"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import pandas as pd\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f269kz5c-P-W"
      },
      "source": [
        "По традиции будем считать, что мы люди сильные и психику портить тоже не хотим, так что справимся без ворнингов))))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTrWj-ts-NEo"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_ZIIFH86wa_"
      },
      "source": [
        "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\r\n",
        "x_train = x_train_pics.reshape(y_train.shape[0], -1)\r\n",
        "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJNN55F7K-hT"
      },
      "source": [
        "__Задание 1. (5 баллов)__\n",
        "\n",
        "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
        "\n",
        "Ваша реализация должна поддерживать следующие опции:\n",
        "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
        "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
        "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
        "\n",
        "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP8yepx8K-hT"
      },
      "source": [
        "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
        "        self.n_features = n_features\n",
        "        self.use_PCA = use_PCA\n",
        "        self.new_dim = new_dim\n",
        "        self.classifier = classifier\n",
        "        self.PCA = PCA(n_components=self.new_dim)\n",
        "\n",
        "        if self.classifier == 'logreg':\n",
        "            self.model = LogisticRegression()\n",
        "        else:\n",
        "            self.model = SVC(kernel=self.classifier)\n",
        "\n",
        "    def est_sigma2(self, X):\n",
        "        batch_size = 1000000\n",
        "        i = np.random.choice(X.shape[0], batch_size)\n",
        "        j = np.random.choice(X.shape[0] - 1, batch_size)\n",
        "        j[j >= i] += 1\n",
        "        ij = np.stack([i, j], axis=1)\n",
        "        sigma2 = np.median(np.sum(np.square(X[ij][:, 0] - X[ij][:, 1]), axis=1))\n",
        "\n",
        "        return sigma2\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if self.use_PCA:\n",
        "            pca_X = self.PCA.fit_transform(X)\n",
        "        else:\n",
        "            pca_X = X\n",
        "            self.new_dim = X.shape[1]\n",
        "\n",
        "        sigma2 = self.est_sigma2(pca_X)\n",
        "\n",
        "        self.W = np.random.normal(0, 1 / np.sqrt(sigma2), (self.new_dim, self.n_features))\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
        "\n",
        "        new_X = np.cos(pca_X @ self.W + self.b)\n",
        "        \n",
        "        self.model.fit(new_X, y)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if self.use_PCA:\n",
        "            pca_X = self.PCA.transform(X)\n",
        "        else:\n",
        "            pca_X = X\n",
        "            self.new_dim = X.shape[1]\n",
        "\n",
        "        new_X = np.cos(pca_X @ self.W + self.b)\n",
        "        res = self.model.predict_proba(new_X)\n",
        "\n",
        "        return res \n",
        "        \n",
        "    def predict(self, X):\n",
        "        if self.use_PCA:\n",
        "            pca_X = self.PCA.transform(X)\n",
        "        else:\n",
        "            pca_X = X\n",
        "            self.new_dim = X.shape[1]\n",
        "\n",
        "        new_X = np.cos(pca_X @ self.W + self.b)\n",
        "        res = self.model.predict(new_X)\n",
        "\n",
        "        return res"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0oR6ZznbCME",
        "outputId": "e7b341c7-69de-4e8a-e81c-f6f0a6a0cef6"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline()\r\n",
        "pip.fit(x_train, y_train)\r\n",
        "y_pred = pip.predict(x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте: \", accuracy_score(y_pred, y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте: 85.94000000000001%\n",
            "CPU times: user 1min 23s, sys: 19.1 s, total: 1min 42s\n",
            "Wall time: 53.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3YkV7uS_JxA"
      },
      "source": [
        "Ну, вроде можно жить дальше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYqQUEi-K-hU"
      },
      "source": [
        "__Задание 2. (3 балла)__\n",
        "\n",
        "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
        "\n",
        "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
        "\n",
        "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oozUaMp5c4b",
        "outputId": "7fac5bc9-081b-4032-c11b-dc0fca148c74"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxtHuliO5zyi",
        "outputId": "714e588a-aafd-4aa5-a9b9-7330e9297ce0"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5XtVTwr6RBr"
      },
      "source": [
        "Рассмотрим случайное подмножество объектов из обучающей выборке, а то иначе SVM будет работать вечность( Я взяла размер равный 1/6 от всех объектов обучающей выборки и также уменьшила размер тестовой выборки, чтобы она была соизмерима обучающей).\r\n",
        "\r\n",
        "Извиняюсь, что так сильно уменьшила, это произошло после того, как SVM на 20000 учился больше 2 часов и я психанула..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duNHA90R5kzF"
      },
      "source": [
        "idxs = random.sample(range(x_train.shape[0]), 10000)\r\n",
        "n_x_train = x_train[idxs]\r\n",
        "n_y_train = y_train[idxs]\r\n",
        "\r\n",
        "idxs_2 = random.sample(range(x_test.shape[0]), 2000)\r\n",
        "n_x_test = x_test[idxs_2]\r\n",
        "n_y_test = y_test[idxs_2]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQYt6hhzWhx1",
        "outputId": "d038b352-8751-47d9-9b7f-345103961c93"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с линейным ядром (RFF): \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с линейным ядром (RFF): 86.1%\n",
            "CPU times: user 39.7 s, sys: 1.42 s, total: 41.1 s\n",
            "Wall time: 39.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jodORVlNNOpq",
        "outputId": "b857b4bb-f019-4a33-8ee9-275329e36fa2"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "model = SVC(kernel='linear')\r\n",
        "model.fit(n_x_train, n_y_train)\r\n",
        "y_pred = model.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с линейным ядром (SVM): \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с линейным ядром (SVM): 79.10000000000001%\n",
            "CPU times: user 40.3 s, sys: 4.31 ms, total: 40.3 s\n",
            "Wall time: 40.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fypPtTWOAGSd"
      },
      "source": [
        "Как мы видим просто SVM справляется хуже, причем в случае линейного ядра я бы сказала, что значительно хуже. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOcem8PUK5uE",
        "outputId": "1116cb83-a530-49df-a35a-78fc57f39041"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='poly')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с полиномиальным ядром (RFF): \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с полиномиальным ядром (RFF): 85.1%\n",
            "CPU times: user 50.9 s, sys: 1.4 s, total: 52.3 s\n",
            "Wall time: 50.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beO6FT-4NtYs",
        "outputId": "85e40d8f-e739-4034-f6de-ebd7b2003205"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "model = SVC(kernel='poly')\r\n",
        "model.fit(n_x_train, n_y_train)\r\n",
        "y_pred = model.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с полиномиальным ядром (SVM): \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с полиномиальным ядром (SVM): 83.55%\n",
            "CPU times: user 42.6 s, sys: 7.45 ms, total: 42.7 s\n",
            "Wall time: 42.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuuKB0yaAhK_"
      },
      "source": [
        "И в случае полиномиального ядра SVM на всех признаках также справляется хуже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxoDYlHRK511",
        "outputId": "719bf546-3ff9-4eb8-f8d5-6316d097a01a"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='rbf')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с Гауссовым ядром (RFF): \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с Гауссовым ядром (RFF): 84.8%\n",
            "CPU times: user 55.1 s, sys: 1.41 s, total: 56.5 s\n",
            "Wall time: 54.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJs7kxaNNuaD",
        "outputId": "3357b22a-b513-494d-b98a-460e42472d79"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "model = SVC(kernel='rbf')\r\n",
        "model.fit(n_x_train, n_y_train)\r\n",
        "y_pred = model.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с Гауссовым ядром (SVM): \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с Гауссовым ядром (SVM): 86.3%\n",
            "CPU times: user 42.9 s, sys: 8.92 ms, total: 42.9 s\n",
            "Wall time: 42.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEd4qUFtAqcY"
      },
      "source": [
        "А тут вот лучше... Ну, не будем особо обращать на это внимание и скажем, почему подход с генерацией новых признаков с PCA работает лучше. Как было сказано (или будет сказано далее, мне лень искать) PCA помогает убрать мусорные признаки, таким образом наш метод генерирует новые признаки из +- нормальных, а значит и они тоже получаются нормальными. И таким образом новый набор признаков может быть лучше, чем исходный и модель на нем будет давать лучшее качество. Вот и все :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0LGiwDMMs-g"
      },
      "source": [
        "Говоря о времени обучения, явным аутсайдером является SVM на исходных признаках. На выведенных примерах это не заметно, но при увеличении числа объектов выборки его время работы ооооочень сильно увеличивается. Я так и не дождалась, когда у меня обучится SVM на 20000 объектах. А ждала я, на минуточку, больше 2-ух часов... В общем, было грустно. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM6SC9wACE6b"
      },
      "source": [
        "Теперь хотим использовать XGBoost И для начала подберем для него параметры - n_estimators и learning_rate. Поиск идет две тысячи лет, так что оставим и там и там по 3 вариации параметров, чтобы примерно понимать, что нам нужно. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrcpaXJWQhbJ",
        "outputId": "a80a7993-ee2b-4f2f-b65f-f27a0eb94c5a"
      },
      "source": [
        "params = {\r\n",
        "    'n_estimators' : np.linspace(10, 50, 3, dtype=int),\r\n",
        "    'learning_rate' : np.linspace(0.1, 0.7, 3),\r\n",
        "}\r\n",
        "\r\n",
        "searcher = RandomizedSearchCV(xgb.XGBClassifier(), params, scoring='accuracy')\r\n",
        "searcher.fit(n_x_train, n_y_train)\r\n",
        "\r\n",
        "best_params = searcher.best_params_\r\n",
        "best_params"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.4, 'n_estimators': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGYeiriLpvw"
      },
      "source": [
        "Да, да, я вижу, что n_estimators вышло равное максимальному порогу... Но на больших n_estimators оно считалось больше 2 часов и моего терпения не хватало("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30BqxZG9NTuv"
      },
      "source": [
        "Теперь обучим XGBoost. Возьмем размерность 50, как было по умолчанию в нашем классе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkeFrhI7QkAb",
        "outputId": "fdc0a6cd-6fa0-412c-e147-125680c6df66"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pca = PCA(n_components=50)\r\n",
        "tr_x_train = pca.fit_transform(n_x_train)\r\n",
        "tr_x_test = pca.transform(n_x_test)\r\n",
        "\r\n",
        "model = xgb.XGBClassifier(n_estimators=best_params['n_estimators'], \r\n",
        "                          learning_rate=best_params['learning_rate'])\r\n",
        "\r\n",
        "model.fit(tr_x_train, n_y_train)\r\n",
        "y_pred = model.predict(tr_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для XGBoost: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')\r\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для XGBoost: 84.35000000000001%\n",
            "CPU times: user 18.4 s, sys: 1.32 s, total: 19.7 s\n",
            "Wall time: 18.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRPKMb3hrqSn"
      },
      "source": [
        "Попробуем еще увеличить n_estimators, так как наш поиск выше выдал крайнее значение, а значит реально оптимальное выше (но с большими числами RandomizedSearchCV работал больше двух часов, так что не судьба)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-hX09q7r_y2",
        "outputId": "4345d0ab-1680-4509-dbe0-44e1eacd6482"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "model = xgb.XGBClassifier(n_estimators=500, \r\n",
        "                          learning_rate=best_params['learning_rate'])\r\n",
        "\r\n",
        "model.fit(tr_x_train, n_y_train)\r\n",
        "y_pred = model.predict(tr_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для XGBoost: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для XGBoost: 85.7%\n",
            "CPU times: user 2min 11s, sys: 92.5 ms, total: 2min 11s\n",
            "Wall time: 2min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asheu44LtKeT"
      },
      "source": [
        "Ну, становится получше, конечно. Но есть ощущение, что до 86.3 (наилучшего результата среди других методов, использующих генерацию новх признаков) все равно не дойдет. Так что скажем, что XGBoost справился с задачей хуже. \r\n",
        "\r\n",
        "Ну и так же XGBoost с достаточно большим n_estimators учился дольше всех, а еще и параметры подбираются просто вечность, так что тут минус по всем фронтам, конечно (прости, XGBoost, ничего личного).\r\n",
        "\r\n",
        "И таким образом, мы пришли к тому, что из исследуемых нами в этом пункте методов, и по критерию качества, и по критерию скорости обучения и применения побеждает подход со случайными признаками. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6umjhWuK-hV"
      },
      "source": [
        "__Задание 3. (2 балла)__\n",
        "\n",
        "Проведите эксперименты:\n",
        "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
        "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
        "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyM313EFZc0i"
      },
      "source": [
        "1) Так как не указано, на чем именно это выяснять, то возьму логистическую регрессию и SVM с линейным ядром и протестирую на них. На это раз будем снова использовать все объекты из выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2QIHIMbK-hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c40e61-99c3-40c9-ac55-3b46f16dc0d0"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для logreg с PCA: 85.85000000000001%\n",
            "CPU times: user 15.2 s, sys: 10.3 s, total: 25.5 s\n",
            "Wall time: 13.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJR42ACVE3UC",
        "outputId": "e8e4b51b-7957-415b-dccb-5b6c41cafb92"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "p = RFFPipeline(classifier='logreg', use_PCA=False)\r\n",
        "p.fit(x_train, y_train)\r\n",
        "y_pred = p.predict(x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для logreg без PCA: \", accuracy_score(y_pred, y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для logreg без PCA: 10.9%\n",
            "CPU times: user 16.2 s, sys: 1.94 s, total: 18.2 s\n",
            "Wall time: 11.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpgggMS3ZttR",
        "outputId": "a6c71546-df2c-44de-dccf-483f77eb7b24"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с PCA: 85.75%\n",
            "CPU times: user 39.3 s, sys: 1.45 s, total: 40.8 s\n",
            "Wall time: 39.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vb05C52aVEG",
        "outputId": "20e7a7e7-96c2-400b-ac2e-b104cef09b68"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='linear', use_PCA=False)\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM без PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM без PCA: 10.549999999999999%\n",
            "CPU times: user 28min 22s, sys: 440 ms, total: 28min 22s\n",
            "Wall time: 28min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjyR2xTBxBH1"
      },
      "source": [
        "Помогает ли предварительное понижение размерности? Ну как вам сказать. Тут проблема в том, что если никак не масштабировать данные, то выходит то, что выше. То есть без PCA качество ну совсем близко к нулю. \r\n",
        "\r\n",
        "А теперь попробуем сделать тоже самое, но отмасштабируем наши данные, чтобы с исходными признаками можно было нормально работать и генерировать из них новые."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUoOc5MiQQV"
      },
      "source": [
        "Простите, тут будет новая подвыборка, потому что я не готова перезапускать весь код выше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1v_s541t_q_"
      },
      "source": [
        "Еще тут возникла проблема с тем, что при нормализации и веторных вычислениях сигмы у коллаба кончается ОЗУ... Так что я просто тестила с циклом в функции, вычисляющей сигму. Решила в итоге оставить векторную версию, она выглядит пооптимальнее для всего остального, но с циклом функция выглядела так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hyKnB83uZR_"
      },
      "source": [
        "\"\"\"\r\n",
        "def est_sigma2(self, X):\r\n",
        "        batch_size = 1000000\r\n",
        "        res = []\r\n",
        "        for i in range(batch_size):\r\n",
        "            ind_1, ind_2 = np.random.randint(0, X.shape[0], size=2)\r\n",
        "            res.append(np.linalg.norm(X[ind_1] - X[ind_2])**2)\r\n",
        "\r\n",
        "        sigma2 = np.median(res)\r\n",
        "\r\n",
        "        return sigma2\r\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msx29lcMiQkE"
      },
      "source": [
        "idxs = random.sample(range(x_train.shape[0]), 10000)\r\n",
        "n_x_train = x_train[idxs]\r\n",
        "n_y_train = y_train[idxs]\r\n",
        "\r\n",
        "idxs_2 = random.sample(range(x_test.shape[0]), 2000)\r\n",
        "n_x_test = x_test[idxs_2]\r\n",
        "n_y_test = y_test[idxs_2]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THawSvFYgBoE"
      },
      "source": [
        "normalized_x_train = n_x_train / 255\r\n",
        "normalized_x_test = n_x_test / 255"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9k0y-fQgB16",
        "outputId": "c8f50f17-5a9c-48f5-86f8-9b1a4feed2f6"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='logreg')\r\n",
        "pip.fit(normalized_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(normalized_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для logreg с PCA с нормализацией: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для logreg с PCA с нормализацией: 85.9%\n",
            "CPU times: user 37.5 s, sys: 10.2 s, total: 47.8 s\n",
            "Wall time: 36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OJ12NsBgcVX",
        "outputId": "9397db7a-0bbd-4038-99c1-836686a2a5d8"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='logreg', use_PCA=False)\r\n",
        "pip.fit(normalized_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(normalized_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для logreg без PCA с нормализацией: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для logreg без PCA с нормализацией: 84.45%\n",
            "CPU times: user 44.1 s, sys: 9.25 s, total: 53.4 s\n",
            "Wall time: 42.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxmJ3Equgcda",
        "outputId": "04e4ac90-5aad-4e1b-95d6-8157a361b455"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='linear')\r\n",
        "pip.fit(normalized_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(normalized_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM с PCA с нормализацией: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM с PCA с нормализацией: 85.5%\n",
            "CPU times: user 1min 7s, sys: 1.47 s, total: 1min 9s\n",
            "Wall time: 1min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fktwq4X0gcp7",
        "outputId": "4623f6ff-473a-4d8a-d1f2-431d4cd2d68b"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='linear', use_PCA=False)\r\n",
        "pip.fit(normalized_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(normalized_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов на тесте для SVM без PCA с нормализацией: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тесте для SVM без PCA с нормализацией: 83.2%\n",
            "CPU times: user 1min 15s, sys: 308 ms, total: 1min 15s\n",
            "Wall time: 1min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLJitV0kuDbD"
      },
      "source": [
        "Как мы видим, при использовании нормализации качество работы моделей с PCA и без PCA примерно сравнимо. И вот тут уже можно сделать вывод о том, что итоговое качество с использованием PCA немного выше, чем без использования. Так что сделаем вывод, что PCA помогает, да. Вообще по сути PCA помогает нам отобрать из всех исходных признаков нормальные. И получается, что в случае с PCA мы генерируем дальше признаки не из всех, что были, а только из +- сносных, когда в случае, если мы не используем PCA новые признаки могут генерироваться в том числе из каких-то совсем мусорных, что, конечно, скажется на качестве (хоть и не очень сильно)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPE6SiYcoF1T"
      },
      "source": [
        "2) Ну что сказать, с SVM-ом мне хочется плакать. А мы, как уже сказано в начале работы, бережем свое психическое здоровье... Так что рассматривать буду логистическую регрессию в данном пункте.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qKtrKcTZtxN"
      },
      "source": [
        "acc_list = []\r\n",
        "n_fs = np.linspace(10, 2000, 40, dtype=int)\r\n",
        "\r\n",
        "for n in n_fs:\r\n",
        "    pip = RFFPipeline(classifier='logreg', n_features=n)\r\n",
        "    pip.fit(n_x_train, n_y_train)\r\n",
        "    y_pred = pip.predict(n_x_test)\r\n",
        "    cur_acc = accuracy_score(y_pred, n_y_test) * 100\r\n",
        "    acc_list.append(cur_acc)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "-OhaxjBKZt2I",
        "outputId": "a5e91227-23fd-42d2-8481-4a2f49eabb2b"
      },
      "source": [
        "plt.figure(figsize=(16, 10))\r\n",
        "plt.plot(n_fs, acc_list, color='deepskyblue')\r\n",
        "plt.xlabel('n_features', size=15)\r\n",
        "plt.ylabel('accuracy (%)', size=15)\r\n",
        "plt.title('Зависимость accuracy от n_features', size=20)\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtOJqlQSszoH"
      },
      "source": [
        "Как можно заметить по графику, итоговое качество растет при росте количества признаков только до определенного момента, а затем уже начинает расти очень медленно/почти не изменяться. Что в целом логично, так как при небольшом количестве признаков (в нашем случае, видимо, меньше 500) их количества может быть недостаточно, чтобы выборка получилась линейно разделимой, чего мы и хотим добиться, используя ядровые методы. А если количество признаков уже достаточно большое, то качество работы растет медленно, так выборка уже является практически линейно разделимой (близкой к этому).\r\n",
        "\r\n",
        "Насчет плато. По графику видно, что где-то начиная с 800 признаков и до 2000 accuracy немного колебалась, при этом оставаясь примерно на уровне 85%. Если это можно назвать платом, то давайте назовем... Кажется, что качество уже все-таки не растет, а просто колеблется между какими-то значениями. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCrv1ismu5HZ"
      },
      "source": [
        "3) Важно ли какую модель обучать? Так, ну разные модели я уже обучала выше, не буду делать тут это снова, просто напишу вывод. Скопируем сюда все наши результаты, потому что я не готова обучать все заново и составлять красивую таблику...\r\n",
        "\r\n",
        "Доля верных ответов на тесте для logreg с PCA: 85.85000000000001%\r\n",
        "\r\n",
        "Доля верных ответов на тесте для linear SVM с PCA: 85.75%\r\n",
        "\r\n",
        "Доля верных ответов на тесте для SVM с полиномиальным ядром с PCA: 85.1%\r\n",
        "\r\n",
        "Доля верных ответов на тесте для SVM с Гауссовым ядром с PCA: 84.8%\r\n",
        "\r\n",
        "Доля верных ответов на тесте для logreg без PCA с нормализацией: 84.45%\r\n",
        "\r\n",
        "Доля верных ответов на тесте для linear SVM без PCA с нормализацией: 83.2%\r\n",
        "\r\n",
        "\r\n",
        "Как можно заметить, и с PCA, и без PCA лучшее качество дала логистическая регрессия. Не сказать, что разница прям коллосальная, но она есть. Из чего можно сделать вывод, что выбор модели все-таки влияет на обучение (что логично, так что я не знаю, что именно от меня хотели услышать в ответе на этот вопрос...)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJqXVuasK-hW"
      },
      "source": [
        "### Бонус"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVDWHCdrK-hX"
      },
      "source": [
        "__Задание 4. (Максимум 2 балла)__\n",
        "\n",
        "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6QF8RE7VJEm"
      },
      "source": [
        "Надеюсь, я правильно все поняла (ай эм сори, ай донт спик инглиш вери гуд, бат ай спик инглиш фифти-фифти) и все, что нам нужно реализовать - это вычисление матрицы W по описанной в статье схеме."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl6EB_-80JG3"
      },
      "source": [
        "<img src=\"https://sun9-36.userapi.com/impf/Bc2Sswyw1j-N62u8ygo7dLHhV6W58L2ft662nw/_52hftRmOJY.jpg?size=1243x357&quality=96&proxy=1&sign=026e2092d206bc01ae20cbe0343d0796&type=album\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxvGI9iK-hX"
      },
      "source": [
        "class ORFPipeline(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\r\n",
        "        self.n_features = n_features\r\n",
        "        self.use_PCA = use_PCA\r\n",
        "        self.new_dim = new_dim\r\n",
        "        self.classifier = classifier\r\n",
        "        self.PCA = PCA(n_components=self.new_dim)\r\n",
        "\r\n",
        "        if self.classifier == 'logreg':\r\n",
        "            self.model = LogisticRegression()\r\n",
        "        else:\r\n",
        "            self.model = SVC(kernel=self.classifier)\r\n",
        "\r\n",
        "    def est_sigma2(self, X):\r\n",
        "        batch_size = 1000000\r\n",
        "        i = np.random.choice(X.shape[0], batch_size)\r\n",
        "        j = np.random.choice(X.shape[0] - 1, batch_size)\r\n",
        "        j[j >= i] += 1\r\n",
        "        ij = np.stack([i, j], axis=1)\r\n",
        "        sigma2 = np.median(np.sum(np.square(X[ij][:, 0] - X[ij][:, 1]), axis=1))\r\n",
        "\r\n",
        "        return sigma2\r\n",
        "\r\n",
        "    def fit(self, X, y):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.fit_transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        sigma2 = self.est_sigma2(pca_X)\r\n",
        "\r\n",
        "        H = np.random.rand(self.n_features, self.new_dim)\r\n",
        "        u, s, vh = np.linalg.svd(H, full_matrices=False)\r\n",
        "        S = u @ vh\r\n",
        "        Q = np.diag(np.random.chisquare(self.new_dim, self.new_dim))\r\n",
        "\r\n",
        "        self.W = 1 / np.sqrt(sigma2) * np.dot(S, Q)\r\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\r\n",
        "\r\n",
        "        new_X = np.cos(pca_X @ self.W.T + self.b)\r\n",
        "        \r\n",
        "        self.model.fit(new_X, y)\r\n",
        "\r\n",
        "        return self\r\n",
        "\r\n",
        "    def predict_proba(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.cos(pca_X @ self.W.T + self.b)\r\n",
        "        res = self.model.predict_proba(new_X)\r\n",
        "\r\n",
        "        return res \r\n",
        "        \r\n",
        "    def predict(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.cos(pca_X @ self.W.T + self.b)\r\n",
        "        res = self.model.predict(new_X)\r\n",
        "\r\n",
        "        return res"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CST1UB_mIONZ"
      },
      "source": [
        "idxs = random.sample(range(x_train.shape[0]), 10000)\r\n",
        "n_x_train = x_train[idxs]\r\n",
        "n_y_train = y_train[idxs]\r\n",
        "\r\n",
        "idxs_2 = random.sample(range(x_test.shape[0]), 2000)\r\n",
        "n_x_test = x_test[idxs_2]\r\n",
        "n_y_test = y_test[idxs_2]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Jx8coQxsB5",
        "outputId": "8ac5cdbc-c495-4bdc-9d8f-dee512fbf0c9"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF на тесте для logreg с PCA: 84.89999999999999%\n",
            "CPU times: user 20.8 s, sys: 13.4 s, total: 34.2 s\n",
            "Wall time: 18.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Rg9kGmGdSj",
        "outputId": "d249507a-a34e-4b27-acd4-dc75d23f4b39"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = ORFPipeline(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов ORF на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов ORF на тесте для logreg с PCA: 85.7%\n",
            "CPU times: user 20.5 s, sys: 12.8 s, total: 33.3 s\n",
            "Wall time: 17.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv9EVV8eHCVb",
        "outputId": "c1b9c1bf-d42b-4372-8fa6-7fca2eefd8c9"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF на тесте для linear SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF на тесте для linear SVM с PCA: 85.39999999999999%\n",
            "CPU times: user 45.9 s, sys: 1.63 s, total: 47.6 s\n",
            "Wall time: 45.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ex7YFcHHC6v",
        "outputId": "8a682f0b-de28-49f3-8991-23a1791cb8dd"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = ORFPipeline(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов ORF на тесте для linear SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов ORF на тесте для linear SVM с PCA: 84.7%\n",
            "CPU times: user 47.1 s, sys: 1.67 s, total: 48.8 s\n",
            "Wall time: 47 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSGmk9RnW-w3",
        "outputId": "064aaa0d-5e89-40c8-b2f1-28793edc9b37"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='poly')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF на тесте для poly SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF на тесте для poly SVM с PCA: 85.1%\n",
            "CPU times: user 57.8 s, sys: 1.75 s, total: 59.5 s\n",
            "Wall time: 57.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY3cSaO5W_Db",
        "outputId": "b937dfd3-c73f-4aaa-8e14-ca903e1820a3"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = ORFPipeline(classifier='poly')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов ORF на тесте для poly SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов ORF на тесте для poly SVM с PCA: 85.9%\n",
            "CPU times: user 1min 11s, sys: 1.69 s, total: 1min 13s\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29BY_INtXQVx",
        "outputId": "084b3499-d14e-429c-8523-aeb63faacbf8"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='rbf')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF на тесте для rbf SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF на тесте для rbf SVM с PCA: 84.3%\n",
            "CPU times: user 1min 2s, sys: 1.63 s, total: 1min 3s\n",
            "Wall time: 1min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDffFp_FXQez",
        "outputId": "071bdd70-e31a-4ad8-ccbd-44085ebd2719"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = ORFPipeline(classifier='rbf')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов ORF на тесте для rbf SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов ORF на тесте для rbf SVM с PCA: 85.75%\n",
            "CPU times: user 1min 5s, sys: 1.64 s, total: 1min 6s\n",
            "Wall time: 1min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb3rMabzYkVf"
      },
      "source": [
        "(С use_PCA тестить не будем, потому что при нормализации у меня вылетает ОЗУ в коллабе при векторных вычислениях, а обратно цикл писать не хочется)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpB2dXgqZfMZ"
      },
      "source": [
        "Ну что ж, как мы видим, в трех из четырех случаев, ORF дал немного более высокое качество, чем RFF. По времени же оба алгоритма работали примерно одинаково. Такие вот дела."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pc7-1jmK-hY"
      },
      "source": [
        "__Задание 5. (Максимум 2 балла)__\n",
        "\n",
        "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWj-O2vjK-hY"
      },
      "source": [
        "class Pipeline_sign(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\r\n",
        "        self.n_features = n_features\r\n",
        "        self.use_PCA = use_PCA\r\n",
        "        self.new_dim = new_dim\r\n",
        "        self.classifier = classifier\r\n",
        "        self.PCA = PCA(n_components=self.new_dim)\r\n",
        "\r\n",
        "        if self.classifier == 'logreg':\r\n",
        "            self.model = LogisticRegression()\r\n",
        "        else:\r\n",
        "            self.model = SVC(kernel=self.classifier)\r\n",
        "\r\n",
        "    def est_sigma2(self, X):\r\n",
        "        batch_size = 1000000\r\n",
        "        i = np.random.choice(X.shape[0], batch_size)\r\n",
        "        j = np.random.choice(X.shape[0] - 1, batch_size)\r\n",
        "        j[j >= i] += 1\r\n",
        "        ij = np.stack([i, j], axis=1)\r\n",
        "        sigma2 = np.median(np.sum(np.square(X[ij][:, 0] - X[ij][:, 1]), axis=1))\r\n",
        "\r\n",
        "        return sigma2\r\n",
        "\r\n",
        "    def fit(self, X, y):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.fit_transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        sigma2 = self.est_sigma2(pca_X)\r\n",
        "\r\n",
        "        self.W = np.random.normal(0, 1 / np.sqrt(sigma2), (self.new_dim, self.n_features))\r\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\r\n",
        "\r\n",
        "        new_X = np.sign(pca_X @ self.W + self.b)\r\n",
        "        \r\n",
        "        self.model.fit(new_X, y)\r\n",
        "\r\n",
        "        return self\r\n",
        "\r\n",
        "    def predict_proba(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.sign(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict_proba(new_X)\r\n",
        "\r\n",
        "        return res \r\n",
        "        \r\n",
        "    def predict(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.sign(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict(new_X)\r\n",
        "\r\n",
        "        return res"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4-rLif2xhJI"
      },
      "source": [
        "class Pipeline_sin(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\r\n",
        "        self.n_features = n_features\r\n",
        "        self.use_PCA = use_PCA\r\n",
        "        self.new_dim = new_dim\r\n",
        "        self.classifier = classifier\r\n",
        "        self.PCA = PCA(n_components=self.new_dim)\r\n",
        "\r\n",
        "        if self.classifier == 'logreg':\r\n",
        "            self.model = LogisticRegression()\r\n",
        "        else:\r\n",
        "            self.model = SVC(kernel=self.classifier)\r\n",
        "\r\n",
        "    def est_sigma2(self, X):\r\n",
        "        batch_size = 1000000\r\n",
        "        i = np.random.choice(X.shape[0], batch_size)\r\n",
        "        j = np.random.choice(X.shape[0] - 1, batch_size)\r\n",
        "        j[j >= i] += 1\r\n",
        "        ij = np.stack([i, j], axis=1)\r\n",
        "        sigma2 = np.median(np.sum(np.square(X[ij][:, 0] - X[ij][:, 1]), axis=1))\r\n",
        "\r\n",
        "        return sigma2\r\n",
        "\r\n",
        "    def fit(self, X, y):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.fit_transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        sigma2 = self.est_sigma2(pca_X)\r\n",
        "\r\n",
        "        self.W = np.random.normal(0, 1 / np.sqrt(sigma2), (self.new_dim, self.n_features))\r\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\r\n",
        "\r\n",
        "        new_X = np.sin(pca_X @ self.W + self.b)\r\n",
        "        \r\n",
        "        self.model.fit(new_X, y)\r\n",
        "\r\n",
        "        return self\r\n",
        "\r\n",
        "    def predict_proba(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.sin(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict_proba(new_X)\r\n",
        "\r\n",
        "        return res \r\n",
        "        \r\n",
        "    def predict(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.sin(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict(new_X)\r\n",
        "\r\n",
        "        return res"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjSFcLTy7oG1"
      },
      "source": [
        "class Pipeline_exp(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\r\n",
        "        self.n_features = n_features\r\n",
        "        self.use_PCA = use_PCA\r\n",
        "        self.new_dim = new_dim\r\n",
        "        self.classifier = classifier\r\n",
        "        self.PCA = PCA(n_components=self.new_dim)\r\n",
        "\r\n",
        "        if self.classifier == 'logreg':\r\n",
        "            self.model = LogisticRegression()\r\n",
        "        else:\r\n",
        "            self.model = SVC(kernel=self.classifier)\r\n",
        "\r\n",
        "    def est_sigma2(self, X):\r\n",
        "        batch_size = 1000000\r\n",
        "        i = np.random.choice(X.shape[0], batch_size)\r\n",
        "        j = np.random.choice(X.shape[0] - 1, batch_size)\r\n",
        "        j[j >= i] += 1\r\n",
        "        ij = np.stack([i, j], axis=1)\r\n",
        "        sigma2 = np.median(np.sum(np.square(X[ij][:, 0] - X[ij][:, 1]), axis=1))\r\n",
        "\r\n",
        "        return sigma2\r\n",
        "\r\n",
        "    def fit(self, X, y):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.fit_transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        sigma2 = self.est_sigma2(pca_X)\r\n",
        "\r\n",
        "        self.W = np.random.normal(0, 1 / np.sqrt(sigma2), (self.new_dim, self.n_features))\r\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\r\n",
        "\r\n",
        "        new_X = np.exp(pca_X @ self.W + self.b)\r\n",
        "        \r\n",
        "        self.model.fit(new_X, y)\r\n",
        "\r\n",
        "        return self\r\n",
        "\r\n",
        "    def predict_proba(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.exp(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict_proba(new_X)\r\n",
        "\r\n",
        "        return res \r\n",
        "        \r\n",
        "    def predict(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.exp(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict(new_X)\r\n",
        "\r\n",
        "        return res"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_T_LrAz8-WT"
      },
      "source": [
        "class Pipeline_log(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\r\n",
        "        self.n_features = n_features\r\n",
        "        self.use_PCA = use_PCA\r\n",
        "        self.new_dim = new_dim\r\n",
        "        self.classifier = classifier\r\n",
        "        self.PCA = PCA(n_components=self.new_dim)\r\n",
        "\r\n",
        "        if self.classifier == 'logreg':\r\n",
        "            self.model = LogisticRegression()\r\n",
        "        else:\r\n",
        "            self.model = SVC(kernel=self.classifier)\r\n",
        "\r\n",
        "    def est_sigma2(self, X):\r\n",
        "        batch_size = 1000000\r\n",
        "        i = np.random.choice(X.shape[0], batch_size)\r\n",
        "        j = np.random.choice(X.shape[0] - 1, batch_size)\r\n",
        "        j[j >= i] += 1\r\n",
        "        ij = np.stack([i, j], axis=1)\r\n",
        "        sigma2 = np.median(np.sum(np.square(X[ij][:, 0] - X[ij][:, 1]), axis=1))\r\n",
        "\r\n",
        "        return sigma2\r\n",
        "\r\n",
        "    def fit(self, X, y):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.fit_transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        sigma2 = self.est_sigma2(pca_X)\r\n",
        "\r\n",
        "        self.W = np.random.normal(0, 1 / np.sqrt(sigma2), (self.new_dim, self.n_features))\r\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\r\n",
        "        new_X = np.log1p((pca_X @ self.W + self.b) + np.max(pca_X @ self.W + self.b))\r\n",
        "        \r\n",
        "        self.model.fit(new_X, y)\r\n",
        "\r\n",
        "        return self\r\n",
        "\r\n",
        "    def predict_proba(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.log1p((pca_X @ self.W + self.b) + np.max(pca_X @ self.W + self.b))\r\n",
        "        res = self.model.predict_proba(new_X)\r\n",
        "\r\n",
        "        return res \r\n",
        "        \r\n",
        "    def predict(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.log1p((pca_X @ self.W + self.b) + np.max(pca_X @ self.W + self.b))\r\n",
        "        res = self.model.predict(new_X)\r\n",
        "\r\n",
        "        return res"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAaMPPwWxhNB"
      },
      "source": [
        "idxs = random.sample(range(x_train.shape[0]), 10000)\r\n",
        "n_x_train = x_train[idxs]\r\n",
        "n_y_train = y_train[idxs]\r\n",
        "\r\n",
        "idxs_2 = random.sample(range(x_test.shape[0]), 2000)\r\n",
        "n_x_test = x_test[idxs_2]\r\n",
        "n_y_test = y_test[idxs_2]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvMME0TixhRl",
        "outputId": "4dfa2212-cb14-48ef-bf82-ff94d2efa9e9"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF на тесте для logreg с PCA: 83.7%\n",
            "CPU times: user 23 s, sys: 14.1 s, total: 37.1 s\n",
            "Wall time: 19.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw6kXxTGflwR",
        "outputId": "11e2edd5-a2b0-4064-952e-7e12b720e719"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_sign(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с sign на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с sign на тесте для logreg с PCA: 80.10000000000001%\n",
            "CPU times: user 23 s, sys: 13.9 s, total: 36.9 s\n",
            "Wall time: 19.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USZ1etYYfmBh",
        "outputId": "9906681c-451f-4ace-c6de-7d8967abc7b1"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_sin(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с sin на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с sin на тесте для logreg с PCA: 83.7%\n",
            "CPU times: user 24 s, sys: 13.5 s, total: 37.5 s\n",
            "Wall time: 19.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4u7NLdEfmOs",
        "outputId": "eb3389cc-f2e2-44d1-cd40-17bd39acec2a"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_exp(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с exp на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с exp на тесте для logreg с PCA: 83.0%\n",
            "CPU times: user 23.2 s, sys: 13.6 s, total: 36.7 s\n",
            "Wall time: 19.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GQ3eQHcfmbs",
        "outputId": "fd82c57b-30ec-4c2c-d396-672b3392b9a3"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_log(classifier='logreg')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с линейным свдигом и log на тесте для logreg с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с линейным свдигом и log на тесте для logreg с PCA: 77.75%\n",
            "CPU times: user 23.9 s, sys: 13.8 s, total: 37.6 s\n",
            "Wall time: 19.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyKrDPTgf2Zs"
      },
      "source": [
        "Как можем увидеть, по времени работы разницы практически нет, все работает +- одинаково (что в целом логично)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dd3ojS288Ru",
        "outputId": "ccd54bff-35ef-4b35-a358-b7028e599310"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = RFFPipeline(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF на тесте для SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF на тесте для SVM с PCA: 83.55%\n",
            "CPU times: user 48 s, sys: 2.8 s, total: 50.8 s\n",
            "Wall time: 49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV_ZGn00g4Rb",
        "outputId": "aa678570-4a0d-4275-f7cb-a0e848850f74"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_sign(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с sign на тесте для SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с sign на тесте для SVM с PCA: 77.14999999999999%\n",
            "CPU times: user 1min 5s, sys: 1.87 s, total: 1min 7s\n",
            "Wall time: 1min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6CEiS6Mg4bp",
        "outputId": "2561c0ce-3a43-4672-b8c2-051b62177734"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_sin(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с sin на тесте для SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с sin на тесте для SVM с PCA: 83.75%\n",
            "CPU times: user 49.9 s, sys: 1.91 s, total: 51.8 s\n",
            "Wall time: 49.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0uIX0zFg4r0",
        "outputId": "a8f946e3-0618-4b45-ff39-473a867bfd1e"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_exp(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с exp на тесте для SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с exp на тесте для SVM с PCA: 80.95%\n",
            "CPU times: user 4min 4s, sys: 2.03 s, total: 4min 6s\n",
            "Wall time: 4min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHFlq4B1g42S",
        "outputId": "6d8ec9de-e44b-49bd-97ea-0f8ff6a7957f"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_log(classifier='linear')\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с линейным свдигом и log на тесте для SVM с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с линейным свдигом и log на тесте для SVM с PCA: 74.75%\n",
            "CPU times: user 51.5 s, sys: 2 s, total: 53.5 s\n",
            "Wall time: 51.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU1XEzVNjgTj"
      },
      "source": [
        "Тут уже можем видеть, что метод с экспонентой работал куда дольше, чем остальные. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV8U7gEc_KEX"
      },
      "source": [
        "В целом, говоря о качестве, можем сказать, что явный аутсайдер для логистической регрессии и SVM - линейный сдвиг с логарифмом, а остальные функции дают примерно одинаковое качество на тесте (вообще, не знаю, что это я за странную функцию решила использовать, но опустим это...).  В итоге ничего лучше косинуса не справилось, ну, это наверное я какие-то слишком рандомные и не очень осмысленные функции взяла. \r\n",
        "\r\n",
        "Ну вернее у нас вышло так, что с SVM лучше справился синус, но тут тоже есть некоторый момент рандома в генерации новых признаков, так что это не показатель, не слишком большая разница. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oags7t0zZqjo"
      },
      "source": [
        "Попробуем теперь сделать что-нибудь с другим классификатором. Рассмотрим Ridge классификатор."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol7le29188Zn"
      },
      "source": [
        "class Pipeline_Ridge(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True):\r\n",
        "        self.n_features = n_features\r\n",
        "        self.use_PCA = use_PCA\r\n",
        "        self.new_dim = new_dim\r\n",
        "        self.PCA = PCA(n_components=self.new_dim)\r\n",
        "        self.model = RidgeClassifierCV()\r\n",
        "        \r\n",
        "\r\n",
        "    def est_sigma2(self, X):\r\n",
        "        batch_size = 1000000\r\n",
        "        i = np.random.choice(X.shape[0], batch_size)\r\n",
        "        j = np.random.choice(X.shape[0] - 1, batch_size)\r\n",
        "        j[j >= i] += 1\r\n",
        "        ij = np.stack([i, j], axis=1)\r\n",
        "        sigma2 = np.median(np.sum(np.square(X[ij][:, 0] - X[ij][:, 1]), axis=1))\r\n",
        "\r\n",
        "        return sigma2\r\n",
        "\r\n",
        "    def fit(self, X, y):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.fit_transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        sigma2 = self.est_sigma2(pca_X)\r\n",
        "\r\n",
        "        self.W = np.random.normal(0, 1 / np.sqrt(sigma2), (self.new_dim, self.n_features))\r\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\r\n",
        "\r\n",
        "        new_X = np.cos(pca_X @ self.W + self.b)\r\n",
        "        \r\n",
        "        self.model.fit(new_X, y)\r\n",
        "\r\n",
        "        return self\r\n",
        "\r\n",
        "    def predict_proba(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.cos(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict_proba(new_X)\r\n",
        "\r\n",
        "        return res \r\n",
        "        \r\n",
        "    def predict(self, X):\r\n",
        "        if self.use_PCA:\r\n",
        "            pca_X = self.PCA.transform(X)\r\n",
        "        else:\r\n",
        "            pca_X = X\r\n",
        "            self.new_dim = X.shape[1]\r\n",
        "\r\n",
        "        new_X = np.cos(pca_X @ self.W + self.b)\r\n",
        "        res = self.model.predict(new_X)\r\n",
        "\r\n",
        "        return res"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cv7mrZXZxkJ",
        "outputId": "375a4ec6-d357-4bec-bff4-a7d5f5220af4"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_Ridge()\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с Ridge classifier на тесте с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с Ridge classifier на тесте с PCA: 84.65%\n",
            "CPU times: user 11.4 s, sys: 2.59 s, total: 14 s\n",
            "Wall time: 8.05 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfmxyas_b5YE"
      },
      "source": [
        "Ridge классификатор даже без подбора параметров оказался лучше всех. Мое уважение.\r\n",
        "\r\n",
        "Попробую еще увеличить количество новых признаков. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IzcFzthd4Ay",
        "outputId": "55dd4ee5-00a7-44d4-a72e-fb682e047aff"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "pip = Pipeline_Ridge(n_features=3000)\r\n",
        "pip.fit(n_x_train, n_y_train)\r\n",
        "y_pred = pip.predict(n_x_test)\r\n",
        "\r\n",
        "print(\"Доля верных ответов RFF с Ridge classifier на тесте с PCA: \", accuracy_score(y_pred, n_y_test) * 100, \"%\", sep='')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов RFF с Ridge classifier на тесте с PCA: 85.2%\n",
            "CPU times: user 1min 34s, sys: 7.42 s, total: 1min 42s\n",
            "Wall time: 1min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQq2F0KTfaNl"
      },
      "source": [
        "Вау, неужели вышло больше 85! На этой хорошей ноте мы и закончим выполнение этого дз)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leDM1lK--YJF"
      },
      "source": [
        "Я не уверена, что очень хорошо сделала бонусы, но! У меня есть кое-что получше...\r\n",
        "\r\n",
        "Грустных мемов больше не будет, они остались на мо-1\r\n",
        "\r\n",
        "Теперь только тик-токи с котиками и собачками!!!\r\n",
        "\r\n",
        "https://vm.tiktok.com/ZSJeu5dDt/\r\n",
        "\r\n",
        "https://vm.tiktok.com/ZSJeuUfgo/\r\n",
        "\r\n",
        "А, у меня еще есть ежик в шапочке панды, точно\r\n",
        "\r\n",
        "https://vm.tiktok.com/ZSJeujPPa/\r\n"
      ]
    }
  ]
}